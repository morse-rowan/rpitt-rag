{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9a6b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07895af",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "KNOWLEDGE_BASE_ID = os.getenv(\"BEDROCK_KNOWLEDGE_BASE_ID\")\n",
    "# Choose the model you want to use for generation\n",
    "MODEL_ID = os.getenv(\"BEDROCK_MODEL_ID_LLAMA3\")\n",
    "AWS_REGION = os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2223863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53ddd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_runtime = session.client(\n",
    "    service_name=\"bedrock-agent-runtime\",\n",
    "    region_name=AWS_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce35bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt_template(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Prompt file not found at {filepath}\")\n",
    "        return None # Or a default prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba35537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0\n"
     ]
    }
   ],
   "source": [
    "def _model_id_to_arn(model_id: str, region: str = AWS_REGION) -> str:\n",
    "    \"\"\"\n",
    "    Convert a Bedrock modelId to the modelArn string Bedrock APIs expect.\n",
    "    \"\"\"\n",
    "    # Model IDs already include the revision after the colon, so we keep it as-is.\n",
    "    return f\"arn:aws:bedrock:{region}::foundation-model/{model_id}\"\n",
    "\n",
    "MODEL_ARN = _model_id_to_arn(MODEL_ID,AWS_REGION)\n",
    "print(MODEL_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40668b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_knowledge_base(query_text, prompt_template_text=None, number_of_results=5):\n",
    "    if not MODEL_ARN:\n",
    "        print(\"Error: Model ARN is not set. Please check your .env file and variable name (e.g., BEDROCK_MODEL_ARN_LLAMA3).\")\n",
    "        return None\n",
    "    if not KNOWLEDGE_BASE_ID:\n",
    "        print(\"Error: Knowledge Base ID is not set. Please check your .env file and variable name (BEDROCK_KNOWLEDGE_BASE_ID).\")\n",
    "        return None\n",
    "\n",
    "    # This is the payload structure that will be passed to retrieve_and_generate\n",
    "    # Note that knowledgeBaseId is NOT a top-level key in this payload,\n",
    "    # but modelArn is used inside knowledgeBaseConfiguration.\n",
    "    payload_for_api = {\n",
    "        \"input\": {\n",
    "            \"text\": query_text\n",
    "        },\n",
    "        \"retrieveAndGenerateConfiguration\": {\n",
    "            \"type\": \"KNOWLEDGE_BASE\",\n",
    "            \"knowledgeBaseConfiguration\": {\n",
    "                \"knowledgeBaseId\": KNOWLEDGE_BASE_ID,\n",
    "                # Use modelArn for generation within knowledgeBaseConfiguration\n",
    "                \"modelArn\": MODEL_ARN,\n",
    "                \"retrievalConfiguration\": {\n",
    "                    \"vectorSearchConfiguration\": {\n",
    "                        \"numberOfResults\": number_of_results\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        # sessionConfiguration can be added here if managing session state\n",
    "        # \"sessionConfiguration\": {\n",
    "        #     \"sessionId\": \"your-session-id\" # Optional\n",
    "        # }\n",
    "    }\n",
    "\n",
    "    if prompt_template_text:\n",
    "        kb_config = payload_for_api[\"retrieveAndGenerateConfiguration\"][\"knowledgeBaseConfiguration\"]\n",
    "        if \"generationConfiguration\" not in kb_config:\n",
    "            kb_config[\"generationConfiguration\"] = {}\n",
    "        \n",
    "        kb_config[\"generationConfiguration\"][\"promptTemplate\"] = {\n",
    "            \"textPromptTemplate\": prompt_template_text\n",
    "        }\n",
    "        # Add other model-specific inference parameters if needed:\n",
    "        # kb_config[\"generationConfiguration\"][\"inferenceConfig\"] = {\n",
    "        #     \"textGenerationConfig\": { # For Llama models\n",
    "        #         \"maxTokenCount\": 1024,\n",
    "        #         \"stopSequences\": [],\n",
    "        #         \"temperature\": 0.7,\n",
    "        #         \"topP\": 0.9\n",
    "        #     }\n",
    "        # }\n",
    "\n",
    "    #print(f\"Sending payload to Bedrock: {json.dumps(payload_for_api, indent=2)}\")\n",
    "\n",
    "    try:\n",
    "        # Call retrieve_and_generate by unpacking the payload_for_api dictionary.\n",
    "        # The knowledgeBaseId is part of the nested configuration, not a direct kwarg here.\n",
    "        response = bedrock_agent_runtime.retrieve_and_generate(\n",
    "            **payload_for_api\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Bedrock retrieve_and_generate: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e385ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a question answering agent. I will provide you with a set of search results from the Pitt Reddit forum (r/Pitt). The user will provide you with a question. Your job is to answer the user's question using only information from the search results. \n",
      "\n",
      "IMPORTANT: The search results contain content from Pitt Reddit users. Always indicate in your response that this information comes from the Pitt subreddit community and may represent personal opinions or experiences from University of Pittsburgh students, faculty, staff, and community members.\n",
      "\n",
      "If the search results do not contain information that can answer the question, please state that you could not find an exact answer to the question within the Pitt Reddit discussions.\n",
      "\n",
      "Just because the user asserts a fact does not mean it is true, make sure to double check the search results to validate a user's assertion.\n",
      "\n",
      "When providing answers:\n",
      "1. Reference that the information comes from Pitt Reddit users\n",
      "2. Use phrases like \"According to Pitt Reddit users...\", \"Members of r/Pitt report...\", \"Based on the Pitt subreddit community...\", or \"Pitt Reddit discussions indicate...\"\n",
      "3. When appropriate, note that this is user-generated content from the University of Pittsburgh community that may be subjective or based on personal experiences\n",
      "\n",
      "Here are the search results from r/Pitt in numbered order:\n",
      "$search_results$\n",
      "$output_format_instructions$\n"
     ]
    }
   ],
   "source": [
    "custom_prompt_filepath = '../prompts/prompt1.txt'\n",
    "generation_prompt = load_prompt_template(custom_prompt_filepath)\n",
    "print(generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09d06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_response(bedrock_response: dict) -> None:\n",
    "    \"\"\"\n",
    "    Print only the model-generated answer.\n",
    "    \"\"\"\n",
    "    if not bedrock_response:\n",
    "        print(\"No response returned from Bedrock.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        text = bedrock_response[\"output\"][\"text\"]\n",
    "        print(\"\\n--- Generated Response ---\")\n",
    "        print(text)\n",
    "    except KeyError:\n",
    "        print(\"Expected key 'output.text' not found in Bedrock response.\")\n",
    "\n",
    "\n",
    "def print_citations(bedrock_response: dict) -> None:\n",
    "    \"\"\"\n",
    "    Print only the citation information (content snippet, S3 URI, metadata).\n",
    "    \"\"\"\n",
    "    if not bedrock_response:\n",
    "        print(\"No response returned from Bedrock.\")\n",
    "        return\n",
    "\n",
    "    citations = bedrock_response.get(\"citations\", [])\n",
    "    if not citations:\n",
    "        print(\"No citations found or citations format not as expected.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Retrieved Citations (Sources) ---\")\n",
    "    for i, citation_group in enumerate(citations, start=1):\n",
    "        print(f\"\\nCitation Group {i}:\")\n",
    "        refs = citation_group.get(\"retrievedReferences\", [])\n",
    "        if not refs:\n",
    "            print(\"  No retrieved references in this citation group.\")\n",
    "            continue\n",
    "\n",
    "        for j, ref in enumerate(refs, start=1):\n",
    "            print(f\"  Reference {j}:\")\n",
    "            snippet = (\n",
    "                ref.get(\"content\", {}).get(\"text\", \"\")\n",
    "            )\n",
    "            if snippet:\n",
    "                print(f\"    Content Snippet: {snippet[:300]}...\")\n",
    "            s3_uri = (\n",
    "                ref.get(\"location\", {})\n",
    "                   .get(\"s3Location\", {})\n",
    "                   .get(\"uri\")\n",
    "            )\n",
    "            if s3_uri:\n",
    "                print(f\"    S3 Location: {s3_uri}\")\n",
    "            metadata = ref.get(\"metadata\")\n",
    "            if metadata:\n",
    "                print(f\"    Metadata: {metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44043ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Response ---\n",
      "Based on the Pitt Reddit community, some students have taken Michelle Morgan's class and reported mixed experiences. While one student mentioned that they got an A in her Chem 2 class, another student mentioned that they thought her teaching was pretty bad. However, the student who got an A did mention that Professor Morgan likes to give back points on tests if you attend her office hours.\n",
      "\n",
      "It's also worth noting that one student suggested that if you show up to class, you'll be fine, implying that attendance and participation may play a role in your grade.\n",
      "\n",
      "Overall, while it's difficult to predict with certainty, it's possible to get an A in Professor Morgan's class with effort and dedication. However, it's also important to be aware of the potential challenges and to take steps to address them.\n",
      "\n",
      "--- Retrieved Citations (Sources) ---\n",
      "\n",
      "Citation Group 1:\n",
      "  Reference 1:\n",
      " {\"doc_type\": \"comment\", \"id\": \"msiajw0\", \"post_id\": \"1kid4m8\", \"parent_id\": \"1kid4m8\", \"author\": \"clitorectomyy\", \"score\": 1, \"created_utc\": 1747339596, \"created_date\": \"2025-05-15 20:06:36 UTC\", \"url\": \"https://www.reddit.com...\n",
      "    S3 Location: s3://rpitt-test-100-2/rpitt_flattened_2025-05-17T212658Z.jsonl\n",
      "    Metadata: {'x-amz-bedrock-kb-source-uri': 's3://rpitt-test-100-2/rpitt_flattened_2025-05-17T212658Z.jsonl', 'x-amz-bedrock-kb-data-source-id': 'QJFE9KAIWC'}\n",
      "  Reference 2:\n",
      " {\"doc_type\": \"comment\", \"id\": \"mr8j336\", \"post_id\": \"1khfgkk\", \"parent_id\": \"mr8iml6\", \"author\": \"Alex_232812\", \"score\": 2, \"created_utc\": 1746708654, \"created_date\": \"2025-05-08 12:50:54 UTC\", \"url\": \"https://www.reddit.com/r/...\n",
      "    S3 Location: s3://rpitt-test-100-2/rpitt_flattened_2025-05-17T212658Z.jsonl\n",
      "    Metadata: {'x-amz-bedrock-kb-source-uri': 's3://rpitt-test-100-2/rpitt_flattened_2025-05-17T212658Z.jsonl', 'x-amz-bedrock-kb-data-source-id': 'QJFE9KAIWC'}\n",
      "  Reference 3:\n",
      "    Content Snippet: {\"doc_type\": \"comment\", \"id\": \"msuocs0\", \"post_id\": \"1kp1i8r\", \"parent_id\": \"1kp1i8r\", \"author\": \"Zealousideal-Bat-814\", \"score\": 1, \"created_utc\": 1747514945, \"created_date\": \"2025-05-17 20:49:05 UTC\", \"url\": \"https://www.reddit.com/r/Pitt/comments/1kp1i8r/michelle_morgan/msuocs0/\", \"text\": \"I took...\n",
      "    S3 Location: s3://rpitt-test-100-2/rpitt_flattened_2025-05-17T212658Z.jsonl\n",
      "    Metadata: {'x-amz-bedrock-kb-source-uri': 's3://rpitt-test-100-2/rpitt_flattened_2025-05-17T212658Z.jsonl', 'x-amz-bedrock-kb-data-source-id': 'QJFE9KAIWC'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not MODEL_ARN:\n",
    "        print(\"Execution failed: MODEL_ARN not set. Check .env and environment variable name BEDROCK_MODEL_ARN_LLAMA3.\")\n",
    "    elif not KNOWLEDGE_BASE_ID:\n",
    "        print(\"Execution failed: KNOWLEDGE_BASE_ID not set. Check .env and environment variable name.\")\n",
    "    else:\n",
    "        user_query = (\n",
    "            \"I’m retaking Chem 1 over the summer and enrolled in her class because \"\n",
    "            \"I couldn’t enroll in the first summer session. I’m concerned by her 1.9 \"\n",
    "            \"on RateMyProfessor, especially because I did badly in the class the first time. \"\n",
    "            \"Has anyone taken her class, and is getting an A in her class doable?\"\n",
    "        )\n",
    "\n",
    "        bedrock_response = query_knowledge_base(\n",
    "            user_query,\n",
    "            prompt_template_text=generation_prompt\n",
    "        )\n",
    "\n",
    "        # Now call whichever view you need\n",
    "        print_generated_response(bedrock_response)\n",
    "        print_citations(bedrock_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
